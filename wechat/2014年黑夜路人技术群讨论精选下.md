> 转载自：<http://mp.weixin.qq.com/s?__biz=MzA3MDA2MjE2OQ==&mid=203562258&idx=1&sn=085296ed8402845c44f8eb14b040ab5c&scene=1#rd>

【09-24】聊聊网站的基本反作弊策略（防抓取，验证码，防垃圾） -- 花生，黑夜路人

1. 验证码   固定时间操作次数限制 - weizhao

2. 这就是一个攻防的问题，没有百分百的解决方案，就看你的网站能给抓取的人带来多少利益，值不值得人家投入精力到攻防中去。 - 付坤

3. 防盗链，防止图片直接被别人直接复制或者通过程序抓取。 - 余辛未

4. 防盗链好做. 防抓取有点麻烦. 我能想到的就是在nginx层用lua和eedis做访问统计 - 花生

5. 防抓去确实麻烦啊，我看那些健康医疗网站用图片的办法来提高抓取的门槛 - skccc

6. 验证码大家就是看看如何混淆和防止ocr - 黑夜路人

7. 防垃圾在于内容频率和内容质量 - 黑夜路人

8. 页面内容可以做代码混淆，让他抓过去也是乱的 - 王斌科

9. 糗事百科以前的web版是这么干的. 但是对于网站来说，还是希望做SEO的 - 黑夜路人

10. 验证码加干扰像素,字体扭曲,不使用同一种字体 - twin

11. 貌似图片化是常规手段，包括京东的价格信息，百度文库和其它很多文档类网站全文图片化 - 水浸街

12. 前端加的透明,小字干扰标签,都是可以被过滤掉的 - twin

13. 现在验证码有打码平台API 简单的能自己识别，稍微复杂的可以打码平台。 只有提高验证码复杂度，不过对用户却不好。 哎，现在也只有这样。 - @理鱼

14. 防止刷票，目前我觉得最稳妥的就是绑定手机了 - @理鱼

15. ajax渲染 - flea

回: 那他抓你ajax接口,都不用解析html了 - twin

回: ajax防不了 - 朝沐金风

16. 抓取工具有几个特征 1. 通过正则匹配头尾,获取你的页面内容, 2. 短时间内高频率并发抓取 3. 与浏览器不同在于,抓取工具只获取页面内容,做字符串处理,不执行js,css代码. 针对抓取,可以根据他的行为,逐步提高门槛 - twin

17. 就是哈，可以在页面内加入一个小标签. 如果是是用户而没有加载这个小标签的话就抛验证码 - 花生

18. @twin scrapy可以设置多代理和抓取频率. @花生 这个和phantomjs结合完爆 - 朝沐金风

回: 是啊,phantomjs我用来做测试,太牛逼了,所以我是偏向于可以被抓取的 - twin

19. 那我能想到的就是两种结合，那就是访问量的统计+标签插入.  这样能干掉绝大多数没技术含量的抓取 - 花生

20. ip黑名单 - flea

21. https://www.centos.bz/2012/12/openresty-nginx-block-cc-attack-deploy/ OpenResty(nginx扩展)实现防cc攻击 - 花生

回: 差不多吧，主要还是频率控制 - 朝沐金风

22. 执行js未执行加验证码， 其实也容易过， 毕竟是客户端传入 - @理鱼

23. 目的都是增加复杂度，让抓取的人考虑，要不要投入精力去搞 - 付坤

24. 先说频率控制 就是防抓取 方案很多 有接入防火墙级别 有接入代理服务器级别 有web服务器级别 有应用级别. 我们能够干涉的只能是应用级别和代理（web服务器）级别的 - 黑夜路人

25. 只要想抓取没有抓不到的，只有通过时间控制。 - 原

26. 先说应用级别怎么做. 在访问页面的时候，你记录一下什么ip啊session之类的特征 - 黑夜路人

27. 对于那种职业化的抓取就没办法了，不管是ip，还是登录才允许访问的账号，都储备着一大批资源，跟这批人斗最累了。 - 付坤

28. 我说一个腾讯某部门需要百度的一些数据，抓取。 用 c++写了一个 http 中间件。 爬虫连接这个中间件， 他们机器多ip多，开上代理，抓的欢乐。 - @理鱼

29. 限制ip访问频率，加验证码，生成图片，脚本处理。 - 原

30. 我有个朋友做抓取的，ip很好搞的，他就搜集网上的sock5代理，能有七八千个ip - lalala

31. 从一些免费代理站上一抓一批，检测一下可用性，再用这批抓来的ip去抓别的 - 付坤

32. 抓取最牛逼的就是用不完的代理ip，任何防抓策略都没用 - 花生

33. 这个我也很好奇，以前做过一个投票网站，有人刷票，防IP根本防不住，全世界各地的IP都有，这那么多代理他们是从哪弄的 - 马犇

回: 五十块钱能保证你同时有几千个ip可用，保持一个月 - 付坤

回: 免费代理网站多的是 - lalala

回: 抓肉鸡的抓完了当代理ip 卖。 淘宝上多的是 - 付坤

34. ipv6后更难防止 - 朝沐金风

35. nginx+lua 可以把不同的cookie 扔到特定的  机器上 比如维护一个小集群A，专门处理这些疑似抓站的ip。虽然不能彻底防范，但是从某种程度上可以不影响正常用户的访问。 - hello

36. 纯的防抓一个页面的内容是个伪命题，或者是在帐号体系下的防抓，防止一些僵尸帐号，广告行为可能还可以。 - lalala

37. 我也觉得验证码最靠谱. 其他方式都能比较低成本的绕过，就图片识别没那么成熟   ，，技术含量也高些，也没多少程序员对这方面有深入的了解. 验证码，可以算防止高频访问的一个低成本，高效果的方案了 - york
　
回:　是啊，对用户的误删也相对较小 - 花生

38. 大家有没有各渠道针对app刷量的防作弊经验呢 - rain

回: lua waf 好几个项目 可以自己综合下. App刷量。设备可以伪造. 绑定手机有手机号码库平台. 上次美团一元看电影 被刷了多少， 我可以说大部分都是被刷量了.防止作弊，的加大统计力度，人工审查力度 - @理鱼

39. 问: 大家怎么防垃圾留言的呢？ - twin

回: Wordpress有个第三方插件 - 萝莉控夫斯基

40. 1、提高发帖成本，防止刷贴，出验证码，不过要结合体验，用一段时间的频率来判断，比如一分钟3次。
2、增加审核机制，反正在大天朝下，只要想做大，内容审核是必不可少的开支，审核机制策略各公司不同，大体上先发后审和先审后发(审核机制可能都能提个讨论话了) - XiangZ

41. 审核用到的技术各公司应该也不一样，我主要见过的有几种:
1、正则做关键词匹配
2、AC自动机做匹配
3、机器学习方面(听过，没接触过)
关键词词库也会做一些不同的分级
全自动的处理没见过，之前做的主要是让审核组维护一套词库 - XiangZ

42. 词库是基本，但是基本上无效. 真正spam你的，不能用词库搞定 - 王瑞珩

43. 人的识别和联想都太厉害了，肯定没办法说完美防得住的，只能是提高别人机器搞你的成本，对于手动spam的，可以通过一些组合策略来处理，还有一些猥琐的手段，比如蜜罐，让他自己玩的hi，减少对系统和其他用户的干扰。 - XiangZ

44. wp的第三方插件叫 Askimet？好像是这个吧 - 青衫隐_刘

45. 这段时间也一直在研究这方面的东西，比较原始的就是根据用户id，用户ip控制访问频率，可以根据秒，分，时等不同粒度进行控制. 这样基本可以挡住大部分啦 - 项超

46. 没有人考虑通过cookie过滤吗. nginx+lua的方式 - hello

47. 但是对于分布式web服务，也就是非单台服务器的情况。对总数的粒度控制需要一些解决办法 - 项超

48. 在proxy层做哈希，固定的uid只会到固定的后端服务！但是这个需要做高可用！ - 项超

49. 前面hello兄提到ngx_lua，剛好我主要開發平台也是ngx_lua/openresty，我目前做法是這樣：

ngx_lua在rewrite phase裡面寫一個lua用來做認證機制，認證主要是對request header or cookie進行decrypt然後獲取真實用戶uid, 最後變成一個uid set成環境變數讓後面的lua甚至PHP可以直接信任這個uid進行業務邏輯操作。

也就是 rewrite_by_lua  ‘header_auth.lua’;    這樣來做authentication
content_by_lua 這部分進行業務主邏輯處理, 或者proxy_pass給PHP甚至nodeJS處理
最後
log_by_lua 這個phase做行為的記錄加總或頻率判斷等邏輯。

舉例，倘若有一個API你不希望被某個mobile device_id，uid, 或某個IP，或某個country_code進行頻繁的存取，你可以在log phase這邊把device_id/uid/ip/country_code這些記錄incr到ngx.shared.DICT同時proxy_pass給另外一個nginx handler, 這個handler往後台的redis進行加總，一旦加總數量到一個threshold之後，在自己的ngx.shared.DICT設一個blacklist flag, 如此接續的請求進來， rewrite_by_lua 這邊看到ngx.shared.DICT這個blacklist flag，就可以直接return 403或一個status:‘fail’ 的JSON返回

如此，rewrite phase處理認證跟ACL control,  content phase處理主業務邏輯，log phase處理稽核與記錄，logging結果同時送往redis進行加總判斷，最後把判斷結果標記在本機的ngx.shared.DICT，如此就變成一個很有彈性的application firewall了，而主程式只要專注在業務邏輯即可，其他都不用管。這是我覺得挺不錯的架構。 - Pahud

【10-28】分享下基于地理位置服务的架构方案？比如:附近的人，附近的商店。 - XiangZ

1. 问: 是不是有些数据库,专门存储和计算地址位置的? - twin

回: 嗯,计算位置倒不是,只是会有标记好的一些酒店餐馆什么的,好像是百度的 - Anonymous、z

2. 最近产品要做一个基于地理位置服务，比如找附近的人，目前网上讨论比较多的方案有两种，一种是二维降一维，把经纬度转换成geohash，根据geohash特性，越多位数相似越接近，通过like 'xxx%'来查找，还有就是使用二维索引，这种mongodb有带。 - XiangZ

3. 建议你用slor来实现。Slor不但可以按距离搜索排序，还可以按相关度等纬度排序，都是现成的功能。 - Mandman

4. 使用墨卡托坐标系. 如果只需要大致位置的用GeoHash就够了，比如微信、陌陌和一些游戏，100米、300米、1000米这样. 如果需要精确位置，那么把经纬度转换为墨卡托坐标系是比较好的方法，一般获取到的地理位置是经纬度，通过经纬度计算距离需要一系列的三角函数浮点数运算，消耗太大，而墨卡托坐标系的度量单位就是米，可以很简单的计算两个坐标点的距离，谷歌地图、微软地图、百度地图等等用的都是墨卡托坐标系或其变种，前面说的GeoHash就是把墨卡托坐标系里的区域划分为一个个矩形并对其编码. -  水浸街

5. 百度的地图服务就很好啊，可以直接查看附近多少米之内的建筑设施，还可以返回名称、位置、type等，判断是酒店餐饮、娱乐等 - 青衫隐_刘

回: 百度地图的数据源是百度自己的，如果你要计算自己的两个用户之间的距离就需要用自己的数据源. - 水浸街

回: 百度也有地址运算就是你说的GeoHash那个东西好像 - 青衫隐_刘

6. 先说经纬度的获取，再说如何找到附近的xx.只说安卓和浏览器，ios更简单. 安卓来说，两个方式，一个是直接安卓的内置api，一个使用第三方sdk. 早期安卓没有内置获取经纬度信息，后来的有了。谷歌官方提供的。另外一个使用第三方sdk，现在百度，高德都提供这个获取经纬度的sdk. 经纬度就是类似：东经103，北纬253 这样的信息，类似x轴和y轴，我们通过这么个东西可以精确定位一个设备在地球上哪个位置.  - 黑夜路人

7. 常规定位一个经纬度是利用卫星的，因为所有位置都是相对的。 一般的gps设备，都是依赖卫星定位，常规是最少三颗卫星定位设备所在的经纬度。所以你用gps设备会告诉你你现在找到了几颗卫星。卫星越多，位置越准. 但是问题来了.比如你在室内，或者是有阻挡的地方没有卫星信号，你如何获取经纬度？这就是大部分车自带的gpa只能室外工作，室内或者有遮挡就不行，哪怕你经过一个天桥，都会告诉你：gps信号丢失.这就需要依赖第二个定位技：手机基站 - 黑夜路人

8. 在没有手机的时代，有个东西叫做卫星电话，这个东西采用的是我们常规技术属于：集中中心式管理. 就是地球上所有卫星电话都依赖于卫星微波通信，到是这个玩意儿有缺点：第一是信号弱经常被阻挡，传输速率只有几k，通信多完全受不了。另外一个就是，政府无法监控，要知道棱镜门的核心就是各种监听监控。电话监控也是各国政府安全部门的要点。但是，优点明显啊，你在海上和沙漠都可以通信，因为是依赖卫星的，并且很安全，所以。卫星电话是各个政府首脑，还有各种黑社会组织首选通信方式。（可以参考电影《窃听风暴》），穷人现在用不起这个玩意儿. 比如美国白宫内部有种电话给总统专用的，叫做“黄机子”，就是电话颜色是黄色的，它就是防窃听的，猜测可能使用了卫星电话技术。（可以参考美剧《纸牌屋》）。我国领导人也有类似的，叫做“红机子”，红色电话，中-南-hai里面用的，也防窃听，不知道技术是否类似美国的。- 黑夜路人

9. 继续说手机，手机的机制跟卫星电话完全不同，是依赖于地面基站的，（又叫蜂窝），大家可以看见路边电线杆上有，跟个音响一样。有些电梯里也有。 手机通信核心依赖各个基站，基站连接到各个地方的节点服务器，然后完成通信。基站是节点式的，跟卫星的区别是稍微去中心化。所以，我们说手机没信号就是附近没基站，或者基站信号太弱。早期，移动，联通，电信，都建设有自己的基站，大家都知道移动信号好，本质就是有钱建设基站多而已，联通信号差（特别地方上），是因为基站建设的少。后来国家发现这个事情很傻逼，因为每个公司都建设一套基站，重复建设，资源浪费严重，所以，今年成立了一个公司，叫做“铁塔公司”，专门从事基站建设，意思是：你们就别建啦，都用我的！解决了资源浪费的问题。（效果如何，待时间来证明）- 黑夜路人

10. 这块科普清晰了吧，继续说手机定位. 手机定位本质是看你手机是连接到哪个基站，来确定你大概位置。一般运营商们会给每个基站编号，比如说上地十街的百度大厦，移动基站编号9527，那么，只要知道基站编码，就知道你在哪个位置了。基站定位缺点也明显啊，就是不精确，因为一个基站可能给周围几百米或者一公里的手机提供服务啊，所以有时候我们看手机地图，会发现自己漂移在另外一条街，就是因为基站定位不精确的原因。 - 黑夜路人

11. 在这个问题上，谷歌又琢磨出一个解决方案，手机不是不准么，嘿嘿，试试wifi啊！又诞生了，wifi信号定位技术.精确度比手机高，室内也能定位，听着就很帅！缺点来了……tmd，我怎么知道一个wifi的ssid叫做：360-wifi-9527的wifi信号在地球哪个角落？谷歌想出了一个妙招，你们猜猜是啥？这个招非常苦逼，哈哈.就是两个字：扫街！谷歌当年的街景车，说是街景，其实还顺便把沿途的wifi信号和地理位置都记录下来了 .有木有很叼炸天的节奏！ 国内一样这么干的是百度，高德，和腾讯 - 黑夜路人

12. 客户端要获取经纬度，直接调用安卓内置api是可以获得的，你不论谷歌是用gps、手机基站、还是wifi信号，反正能够给你获得经纬度，你用就行了。国内的经纬度，百度、高德、腾讯，做得都不错，因为他们的车子也出去扫wifi信号去了。不过wifi信号有时候会换，相应他们也会做更新，是否会从客户端偷数据回去，这个不知道。反正会比较准就是了。- 黑夜路人

13. 如果想要在安卓浏览器上面获取这些信息，同样的，调用api，就是在你的html5页面里面输出相应的东西，然后页面会问用户是否需要访问用户位置，用户同意了就可以用，你访问滴滴打车，美团之类的就会看到这个提示。但是浏览器调用的api跟你自己安卓 native app获取信息差不多，不过就是比较繁琐，用户会不乐意，所以 web app这个活不好干呐。- 黑夜路人

回: html5的geolocation API… - 朝沐金风

14. wifi定位精确度很低的 - 朝沐金风

回: 如果不是你们家wifi当然不高，但是也是没办法中的办法。最精准非GPS莫属了。 - 黑夜路人

回: 所以一般最优先的是gps. 精度在20米. 然后是移动基站定位 - 朝沐金风

现在的室内定位技术，能够做到定位你再商场第几层哪个商店门口。。。尿了。。。。 - 黑夜路人

15. 现在你经过千辛万苦，依赖内置api或者第三方sdk，获取了用户的经纬度，传递给了服务端，现在服务端如何帮助你找到附近的xx呢？（比如附近的炮友。。。） 上面我看到大家讨论了几种方案，大体是这几种方案。

1. 使用GIS的数据库引擎。（Geograhpic Information system，地理信息系统）。
2. 使用PostGIS第三方扩展
3. 使用类似GeoHash类似的做法
4. 部分内置了 空间索引与空间查询 的数据库（非GIS引擎）

第1种，目前支持最好的是PostgrSQL，使用PostGIS扩展，能够获得很好的gis操作。mysql 一直在gis方面支持不太好，但是从mysql4.1开始，mysql就引入了一系列空间扩展，使其具备了一定的空间处理能力。

第2种，不用说了，很著名的 PostGIS，大家可以研究下。

第3种，GeoHash，是一种处理算法，大致就是把全球定位成一个个个子，你大致属于哪个格子，你就是能够找到附近的人或店。这个不需要GIS引擎支持，算法就能够支持，就是运算量比较大。参考这篇文章：http://blog.csdn.net/heiyeshuwu/article/details/34476491

第4种，类似于第1种，目前支持最好的就是MongoDB内置的原生地支持了空间索引与空间查询，不需要依赖PostGIS这种扩展，可以直接使用，比如输入一个精度，给出附近某个范围的其他数据。操作比较简单。 - 黑夜路人

16. 问: GIS数据库怎么理解？求科普 - 水浸街

回: GIS数据库是某区域内关于一定地理要素特征的数据集合，主要涉及对图形和属性数据的管理和组织。 - 黑夜路人

回: 什么原理

回: 我发一个官方描述：与其它数据库相比GIS数据库有着自身的一些特点：⑴ GIS数据库不仅有与一般数据库数据性质相似的地理要素的属性数据，还有大量的空间数据，即描述地理要素空间分布位置的数据，且这两种数据之间具有不可分割的联系；⑵ 地理信息系统是一个复杂的巨系统，用多种数据来描述资源环境。即使是一个极小的区域，数据量大；⑶ 数据库的更新周期比较长，且不是适时更新，它更多的是提供查询作用。上述特点，决定了建立GIS数据库时，一方面应该遵循和应用通用数据库的原理和方法，另一方面还必须采取一些特殊的技术和方法，来解决其它数据库所没有的管理空间数据的问题。 - 黑夜路人

17. 地理位置获取的，还有一种，精度很低，感觉不是很靠谱geoip。通过IP获取大致地理位置。
之前知道创宇在openssl心脏出血漏洞的时候做了一个 ZoomEye监测“心脏出血”漏洞全球分布图，应该就用到这个 - XiangZ

18. 问: geoip 不靠谱的原因是?
我看新浪微博的数据就有geo字段 - Micarol

回: 比如，我现在的路由器翻墙了，用geoip就不是我这里的位置了，而且IP很难定位具体位置，大多数只能把行政中心的位置定义为IP位置，所以不准，但是在大场景，不需要很精确的服务，比如分布图这样的，可以用 - XiangZ

19. ip定位是传统的定位技术，在pc时代就有，但是又了手机这种设备，它就很out了。现在不是很多各种ip库，就是依赖ip定位。比如 ip138.com，能够查询ip位置，还有纯真ip库，高春辉的17mon IP库等等。 国内互联网公司，在ip数据库方面做得最好的是腾讯，数据挖掘的非常棒，通过一个ip，知道这个人是什么场景下上网的，是干嘛的，消费能力如何等等。 其他互联网公司，都有自己的客户端，通过客户端获取用户ip和位置，各有各的绝招。不过也有偷别人ip库信息的。 - 黑夜路人

20. 纯真ip库结构解析：http://www.cnblogs.com/analyzer/articles/1726143.html - 黑夜路人

21. Mongodb 查询经纬度：http://www.2cto.com/database/201406/305985.html - 黑夜路人

22. 大致了解了一下空间数据库，应该就是可以存储对象的数据库这个意思. 比如一个点在数据库里是一个对象，一张图也是一个对象. 对于需要功能比较复杂的GIS系统还是很不错的，但对于互联网访问这种功能简单、访问量大的估计数据库部分开销会太大 - 水浸街

23. 我了解的arcgis里面除了存普通的属性表数据，还存储拓扑信息 - 李明

回: 拓扑信息是计算路径需要的吧，比如百度地图上从a点到b点怎么走 - 水浸街

24. 存储只是点线面. 现在精度误差其实已经没有了. 政府不允许 。所以地图厂商会人为纠偏 - flea

25. 服务端获取手机端ip时，如果手机通过基站上网，记得是有 手机归属地与 手机所在地之分 - ten-ten

26. 室内定位可以看下美团的方案 - flea

回: 美团的室内定位，应该是这个吧 http://tech.meituan.com/mt-wifi-locate-practice-part1.html - XiangZ

27. 我知道有创业公司在做大型卖场的免费wifi，一个功能是到达某个店铺会发送促销广告，另一个功能应该就是室内导航功能，可以与第三方合作 - 水浸街

28. 数据库postgre. 目前它是支持空间数据最好的数据库 . 流通数据格式geojson. 搜索用芒果 ，solr, elasticsearch 都行.  - flea

29. 这样其实挺蛋疼的 太杂乱了. 全国点数据量没法用pssql很好点解决. 我们目前路表数据就有十几亿条. 现在初步用redis先起步. 正在把数据全部静态化到内存中 不去请求redis了. - 闵敢

30. 附近的 商店 这个功能很好实现 因为 经纬度都是静态的 所以用sphinx就能搞定 具体函数 SetGeoAnchor    附近的人比较麻烦 因为经纬度都是实时变的  可以用redis+Geohash实现 - 刘祥昆

31. 用mongodb可以支持附近的人，某个区域(多边形)内的人. http://docs.mongodb.org/manual/tutorial/query-a-2dsphere-index/   坐标一般用geojson存储，数据量大的话可以做分片，目前我用的感觉还不错 - 风之缘

回: mongodb感觉不是一个好方法  不如自己用更简单的来做
访问量不是特别大的话 redis就可以 - 闵敢

【10-29】分享下各位公司的代码管理和发布机制 - 大胖

1. 我们php项目，代码管理svn当然git也一样。 开发提交开发库，svn up到测试机测试，测试机有同步一些线上数据。测试除了本人测试一边外，同事也测试一遍（最早只测试一遍后来发生过不少问题，为什么自己测试，小团队，没测试，都是开发自己测）。通过后合并到线上发布库。 线上svn up发布。.svn怎么处理，用nginx给控制不能访问  - @理鱼

2. 问: svn up是自动的？

回: 可以做自动 但是我们手动 - @理鱼

回: 测试时一般不做自动,因为可能开发一提交,测试环境就挂了,测试工作就停了 - twin

3. 用ansible 开发一个运维平台 都做成 web管理都ok  应为小所以都在忙业务 没精力搞这些 - @理鱼

4. 早期人少的话,发布就很简单了, 线上也搭个git,写个crontab每分钟拉一次数据. 或者象sina sae,写个svn钩子,提交就发布 - twin

5. 最好是写个管理平台，人为控制发布和回滚 - 朝沐金风

6. 俺们的发布系统svn + rsync，后来改成svn + saltstack - 叶金荣

7. jenkins. saltstack算比较新的吧 - 潘

8. 新浪内部用的发布平台挺好。人为控制发布回滚。sae是钩子。有提交就发布。我们用的方式是最普通的方式。开发环境钩子发布。上线的时候合并代码到仿真环境进行测试。最后测试通过通过命令行调用svn发布。 - 念念念恩他爹

9. 问: 发布时,同时把素材发布到cdn,大家是怎么做的呢? 除了等cdn生效,有其他办法立即生效吗? - twin

回: 发布到CDN然后修改版本号. 简单粗暴 - 念念念恩他爹

回: 修改？v=123. 123是变量. 这样推的新素材. 不用管cdn - @理鱼

回: 不是版本号问题. 一般发布到cdn,cdn要下发素材到各个节点,这时候静态素材有一小段时间访问不到 - twin

回: 怎么会访问不到，没有源么 - @理鱼

回: 回源怕压力大吧哈哈 - 念念念恩他爹

回: 是啊,我知道回源的可以,在想有没其他办法 - twin

10. jenkins的原理也是svn/git 必要的语法检查 然后sync发布代码到各个节点 - 潘

11. 如果项目不是很大 用Jenkins还是比较耗成本的 - 秦培荣

12. 以前公司也是用SVN+RSYNC，然后做了套WEB管理系统 - 大胖

13. 目前代码管理都是git和SVN，估计大都是是SVN. 发布目前我们使用自己编写的自动发布脚本，基于fabric和rysnc - ace

14. 我们目前是git管理代码，SVN发布 - Saaremaa

15. 问: 除了代码,发布时的SQL语句,数据更新脚本要怎么执行好呢? - twin

回: 之前我们内部讨论过这个问题，写脚本比较正规，但是时间成本高，目前还处于手动同步状态 - ace

16. 有一个 开原 的 叫sync 的 上线系统
vriteam.com 这个不错 - 姚文强

17. 问: 如果本次发布，调整了数据库中的表结构，发布一段时间后，发现有个很大的问题，影响面很大，代码需要回滚，这时候已经插入新数据了。遇到这种情况该怎么办？ - XiangZ

回: 这种如果问题能扛，就修改代码修复问题，不回滚数据。实在不行的话就只能回滚数据，切回备份的数据了，那些新数据只能再写处理程序转回旧格式的数据 - 风之缘

18. 我说下我们的吧. 我们是4个版本库， dev qa preview rc. 上线是一级一级合. 文本形式写更新说明. 上线有上线平台，开发只到能上到qa后面都是运维操作 - tywei

19. 问: preview是给哪些人跑呢 - 李智

回: preview的数据库连的是线上的，代码是分开的 - tywei

20. 我们使用svn，建立开发库和测试库，开发人员自测通过后提交到测试库，测试人员测试通过后再发布。数据库模型使用PowerDesigner设计，任何数据库变更包括配置数据变更均需要提交db变更申请，SQL脚本由dba负责生成。内部开发了一套管理系统，需求、任务、变更申请、发布等均在这套系统上操作。 - 水浸街

21. 我们使用git tag发布 - 沙漠风暴

22. 赞，你们是代码和容器打包一起发？还是代码只归代码发布？ - 一席

回: 我们只发代码  之前是svn  现在是git - 刘祥昆

23. 通过脚本rsync将发布代码推送到线上，需要删除 - 昱北

24. 打完包批量scp  生产环境保留3个历史版本。 - 一席

25. 历史遗留问题一直没人改进，一般应该有发布系统吧 - 昱北

26. 线下发布用jenkins 线上发布自己写脚本或者工具 - 张浩

27. 用gitlab做托管，发布系统来管理ssh key，线上服务器git checkout 版本号 - -_-

28. twitter用的是bt，我之前推文件，最先用的是hadoop，后来尝试了bt. 单纯的在推代码的角度来说 我是这么尝试过，其实我推的也不是代码，就是一个700M的文件。 - hello

29. 嗯，我们目前有个publish集群，专门是做分发的. BT分发 和批量scp  都用过，规模大了，个人觉得差不多的. 其实 这个问题主要是减少 发布 时间，包括分发时间，流量开关时间，应用启动时间。发布过程要减少对用户的损失 体验。各种系统间的发布依赖，和各种情况，让发布系统解决。 - 一席

【11-19】如何排查系统问题和瓶颈？ - 黑夜路人

1. 计划任务php进程没跑完就停了，会可能是哪些原因？求助. 没有错误和异常. 没错误日志. 整个流程有try catch. 有写大量日志. 可复现 - 泉-June

回: 你用一下shutdown dunction那个函数看看发生了什么呢 - 花生

回: php 有时会因为扩展而终止，有时没有异常日志，但可用xdebug trace 能找出最后的执行语句。你可试试. get post 加XDEBUG_TRACE 条件出发 - hilojack

回: 在各位帮助下找到原因，写日志太多，未写入前积累爆内存 - 泉-June

2. 如果是c或c++的程序，进程异常退出会产生core文件，php以及扩展是c写的，可以用gdb来看看core在哪了 - 水浸街

3. 问: 之前有遇到过生成好多.core文件到硬盘上   还好服务器硬盘还够  大家有碰到过吗 - 汉族教父

回: 可以设置的，包括大小限制和路径、是否覆盖，上百度一搜就有. 不要扩展名就只有一个core文件，就不存在占用空间问题了，我们的生产系统都是这样. /proc/sys/kernel/core_uses_pid可以控制core文件的文件名中是否添加pid作为扩展。文件内容为1，表示添加pid作为扩展名，生成的core文件格式为core.xxxx；为0则表示生成的core文件同一命名为core。 - 水浸街

回: 是不是把这个参数设成0就会一直写到一个不带pid的文件了  否则会每次生成一个带pid的core导致磁盘爆满 - 汉族教父

回: 是的，不过core很频繁应该想办法解决，肯定是程序设计的问题 - 水浸街

4. 我们有一部分后端是用c++写的，回到今天的话题，解决问题用得最多的是gdb，然后是pstack、pmap、nm、ldd、top这些来定位问题，不知道用在php写的系统是否可以，前端用得最多的是httpwatch - 水浸街

5. 问: 麻烦解释下什么core - @理鱼

回: core文件是系统生成的. 一般是段错误引起的，就是常说的内存操作错误. core文件的生成过程叫做coredump. core文件一般是运行时整个进程操作的各种资源内存景象信息，还包括代码。为了保证core文件可读，gdb编译的时候不要使用太高的优化，就是-o参数，否则你会啥的看不了的. 记得貌似要打开-g参数。才能看到源码，细节搜索下. php生成的core文件默认在webroot目录 - 黑夜路人

回: 打开-g也得有源码的情况下才能看到吧，没有源码顶多查看堆栈的时候看到个函数名，甚至函数名也看不到 - 马犇

回: php 不清楚，c.c+ 需要可执行文件或者类库，
具体搜索下: gdb coredump - 林浩杰

回: 用gdb编译的时候开启这个选项 - 黑夜路人

回: 不需要源代码 编译加上-g - 林浩杰

回: 你编译当然有源码了，汗 - 黑夜路人

回: 如果你调试其他没有源代码 编译不给你加 这个东西 你也无能为力了 - 林浩杰

回: -g会附带符号信息 用于调试 - 朝沐金风

6. php编译的时候貌似需要加上--debug选项. 然后出coredump的时候才有文件. 另外一个是要打开linux内核设置的core file选项. 一般很简单，用ulimit为无限就行了. 然后，写个脚本监控一下webroot. 目录下有木有core文件就行了 - 黑夜路人

7. 一般做过linux下面c开发，这些套路都懂，恩。所以建议做做基本的c开发. ps：golang编译的二进制可以直接用gdb来调试哟  - 黑夜路人

8. 一般追查，当然二话不说看日志了. 先看现象，比如是打开页面慢，还是直接打不开，或者接口不能用. 一般先判断物理是否故障. 比如用ping啊，查看nslookup域名解析啊. 如果完全ping不通，或者国内ping的网络耗时很高，说明要么你本地网络有问题，要么服务器网络有问题。一般网络，无非机房故障，或者服务器网卡被打满，或者被DDOS攻击了。也可能域名被劫持。 - 黑夜路人

9. 如果物理没问题，就开始看系统。一般追查从接入层，比如CDN，或者vanish，或者lvs，haproxy，或者nginx开始. 有的可能是lvs挂了，无法顺利分发请求，那你就跳过lvs，自己直接设定一个服务器的ip来测试。有些可能cdn或者vanish挂了，测试看看。 - 黑夜路人

10. 如果接入层没问题，就开始检查应用层. 一般就是web服务器啊，php之类的. 比如你用的是nginx，发现500之类的，可能就是nginx有可能有问题。比如报502之类的，那么不出意外，就是你php-fpm有问题. 如果只是响应很难，那可能是php有问题，因为nginx一般出问题比较少. - 黑夜路人

11. 一般看看nginx的错误日志，比如说502 日志里是upstream time out，就是php响应太慢无疑了。因为一般fastcgi会有超时设置，包括连接超时，读超时，写入超时等，所以看到这条日志，就去看你的php是啥情况吧。一般php-fpm可以，简单看看起来了几个进程。有没有僵尸进程。php追查最主要依赖日志，包括php错误日志，还有php fpm  slow log等。 - 黑夜路人

12. 错误日志里一般能够看到比如了解memcache或者mysql连接错误等等。比如看到mysql错误，什么too many  connection之类，就是mysql连接太多挂了. 实际情况会比较复杂，因为业务不会只是访问一个后端，可能各种后端，有时候，基本的php  error log大部分信息没收集到。所以，这个时候，一般推荐php代码要多打印日志。特别后端连接和各种读写操作的日志，特别时间耗费日志。 - 黑夜路人

13. 我想判断用户端故障，这个我搞的太多了远程不下于200个用户的电脑. 我比较二了。  说说我的过程。
故障现象， 移动用户无法访问
1、 ping检查，nslookup检查， 检查域名解析的ping是否为自己的节点ip，是否解析为对应的调度ip   如果解析的不对，检查用户dns配置。
2、ping检查，nslookup检查通过， 不管是能ping 还是 无法ping 的情况。
使用telnet 检查端口  telnet 8.8.8.8 80 检查是否通。 如果80也不通，试试换一个你自己的开了其他端口的ip 比如 4.4.4.4 22 看看是否能telnet - @理鱼

14. 移动线路跨isp访问电信老出问题。 用户重启路由器后，换一移动ip就可以访问了。 后来实在是烦，部署了bgp节点后解决移动的问题。
移动还有个其他问题。 - @理鱼

15. 故障现象。 用户访问不了网站。 打开页面提示 一些其他http 错误。 比如 403 404等 。  远程用户后发现这个现象太奇怪了。 解析都ok。 telnet 80 也通。  然后我检查http header头发现了猫腻。 发现移动使用了强制http正向代理缓存。  原来是尼玛，南通移动用了蓝汛的强制http正向代理缓存出了问题。 这个问题当时没法处理，后来自己恢复的。- @理鱼

16. 这里送一句我的开发格言：“好的日志记录能够帮助你避免和排查解决80%的线上问题。” - 黑夜路人

17. 路人兄说的。 我补充下我的。  我把php 和mysql的 slow慢执行，慢查询都打开了。 对排错非常的有用。   mysql的 慢查询记录，配合慢查询分析工具， 分析的结果来优化sql。  优化sql本身，优化索引，到分库，分表等。  php的慢执行，可以用xhprof来追踪优化处理。大多数情况，php的慢执行，都是数据库瓶颈这里。- @理鱼

18. 一般线上情况，基本都是后端慢或者某个后端服务挂了引起的，小部分情况是php写太烂引起的bug或者性能太差，所以，不要招太差技术的php开发人员。 - 黑夜路人

19. php排查，能够借助的工具是：日志记录，xphrof/xdebug。一般情况，日志记录够用了，除非想做大性能优化，才考虑，又或者你偷懒不想看别人代码，那就用xprof吧。 - 黑夜路人

20. 关于mysql连接过多的问题。 其实基本都是因为mysql的慢查询阻塞导致的。 一味的开大mysql的连接数实际上并不能提高mysql的处理吞吐。- @理鱼

21. php说完了，我们再往后端说。假设你在php层追查发现是mysql比较慢，那么，我们就去追查mysql的问题。 有请  @叶金荣 来说说，哈 - 黑夜路人

回: 20141024程序员节分享：一步到位实现MySQL优化的PPT、录音、视频观看地址：
微博微盘：http://t.cn/R7xBs2d
搜狐视频：http://t.cn/R7xBgwz
百度云盘：http://t.cn/R7xBs2e -

这里有啊 ：） 大家耐心听完. 其实工具和方法无非就那几个，有些怪异问题更多靠经验以及判断力 - 叶金荣

22. 对MySQL，一般而言，瓶颈主要在磁盘IO. 最常见最弱智的就是索引了. 索引不当，会导致磁盘IO很高，CPU很高. 如果发现CPU的%USER跑得很高了，这时候第一反应就是查索引问题 - 叶金荣

回: 咋看索引问题呢 - 黑夜路人

回: slow log先定位 - Demon

回: EXPLAIN. 有索引的，也有可能进slow log - 叶金荣

23. ORM也会导致系统慢,几个方向排查

a. select语句默认查询所有的字段 => 通过select('field1, field2')指定字段,排除text字段,text字段分表
b. relations导致的关联查询 => 可以的话,拆成两句,充分利用数据库索引,缓存
c. 反射数据表,生成中间文件,解析配置导致慢  => 启用缓存
d. 类库太大,导致PHP加载慢 => 启用apc,opcache,autoload缓存 - twin

24. 分享一张图片，Linux分析调优工具 http://www.beginningwithi.com/wp-content/uploads/2013/02/Screen-shot-2013-02-28-at-8.49.35-PM-624x466.png - 水浸街

25. 问: 如果遇到memcache写入频繁，怎么定位是哪个程序在写 - hei

回: 访问频繁可以使用网络监测工具实现，如netstat、nethogs等，写入频繁涉及到应用协议了，找一下memcache相关的监测工具看 - 水浸街

【11-24】到数据表取一堆未处理的数据用接口处理，然后根据结果在表标志已处理，用计划任务，如何实现并发？ - 泉-June

1. shell 配合php， 执行一个php任务时， 在shell中使用wait，- Meow

2. 加锁就行了，或者把数据块处理 - 黑夜路人

3. swoole可以帮到你. 多线程，异步. 如果用Erlang,golang就个简单就可以实现 - 陈周瑜

4. 其实我是想用原生php实现. 因为想简单的同时自己多点了解. 如果是加锁怎么做呢 - 泉-June

5. 用pcntl. php原生的多进程. 只能在linux的cli模式下运行 - 陈周瑜

6. 跟多线程无关. 它关键是数据共享，必须对数据不会重复处理. 多线程多进程都能解决并发处理问题 - 黑夜路人

7. 是啊,之前讨论过, 你要么就加锁,遇到锁的数据跳过,要么是读的数据不一样 - twin

8. 你是数据库还是文本文件？如果是数据库，有个最简单的方法. 比如说你先统计出总共有多少要处理的数据. 然后按照你每个进程要处理数据的数量分段. 比如说你1000条记录，每个进程处理100个，就分10段，起10个进程. 然后每个段你获得起始处理id，然后每个进程从自己开始数据段位置开始处理，依次执行。 - 黑夜路人

9. 分段呗. 一个进程处理一段. 最简单了. 在一个文件里面记录你这次处理了多少. 下次处理后面的 - 花生

10. 不借缓存，队列. 表的数据会不断增加. 其实是一个进程，五分钟一次，担心处理不完，第二次任务起来 - 泉-June

回: 这也简单，加锁，文件锁. 用文件锁保证单进程运行. 我去年搞百度经验时都用过 - 花生

11. 如果你数据库是一直在动态增长的话，就需要对这些进程进行调度了. 很简单，就是用动态生成处理进程的方式来处理。比如说你发现五分钟内一个进程最多可以处理100条记录，而你启动的时候最近五分钟已经生成了880条记录。那么你就fork8个处理进程就行了。这个每个五分钟处理多少数据量，需要你自己观察记录统计出来设定一个合理的值。 - 黑夜路人

12. 关于加锁的问题. 比如你担心两个五分钟中间会处理不完，一般做法是处理进程启动的时候生成一个lock文件，进程启动判断如果存在lock文件。进程就认为上个进程处理没完成，就不会启动自己。进程处理完就把这个lock文件删除，就是解锁的操作。 - 黑夜路人

13. 但是问题又来了，如果上一个进程持续处理不完，那么下一个crontab启动新进程来运行，发现上个进程没有结束，自己就不启动，这个时候数据库的数据会不断累计，数据更多，你必须等到下个五分钟等crontab调用，才能进行下一轮的执行，后面就数据量很多，依次这么下去，变成恶性循环，就悲剧了。 - 黑夜路人

14. 简单解决方案就是我上面说的，按照当前数据量动态生成处理进程来处理，每个处理进程处理数据量按照你统计是在五分钟内可以处理完的最好。 - 黑夜路人

15. 还有个细节，你需要在启动执行的时候记录你处理数据是哪个时间范围内的，所以，你需要记录你扫描数据库那个时间范围的数据，就需要记录一个时间点。 - 黑夜路人

16. 我现在的做法是，一个进程，五分钟一次，代码循环一千条一次，每次写最大id到文件，循环里条件就是读最大id,做下次循环，不管多少进程 - 泉-June

17. 存储id或者时间都行，id精确些 - 黑夜路人

18. 其实这里设计关键. 就是进程管理. 所以，进程管理需要设计成类似nginx的 master/woeker 的模型。 - 黑夜路人

19. 集中管理. 分散处理. 按照这个思路就应该是对的 - Jason Bourne

20. 生成多少个进程，生成锁文件，检查是否启动等等，都需要master进程来负责，具体处理逻辑和工作的就是worker进程负责。- 黑夜路人

21. 可以按生成时间加一个取数据限制避免重复操作 - 亢

22. 如果想通用解决方案，可以把上面这个思路设计成框架，就是把进程调度加锁等作为基础，但是具体表结构和处理逻辑就是变成回调接口，这样就通用化了，就是一个能够处理所有类似的问题的框架了。这就是架构师思维了。 - 黑夜路人

23. 问: 那刚才说到的重复数据怎么处理 - Anonymous、z

回: 上面这个机制不会重复数据 - 黑夜路人

24. 问: 那失败要重发的怎么处理呢? - twin

回: 如果逻辑处理失败。建议记录到错误日志。或者记录到临时表或者redis. 下个master启动的时候，单独fork一个进程去扫描日志文件或redis去逐个处理，处理好了删除。或者单独启动一个php程序去处理也行，都可以。 - 黑夜路人

回: 应该用时间分段吧, 那些明确要重发的,只是改个时间标志, 下次进程就会读到这个记录了, 这样不用写多一份失败处理逻辑.  用id的话,就插入一条新记录到最前面了 - twin

回: 呵呵，也可以，不依赖外部存储。看各个业务了，有些不想更改原始数据。如果你错误数据比正确的还多，那你这个后段服务就有问题了。哈哈. 你得查查问题在哪儿。 - 黑夜路人

25. 上面相同问题用c/golang解决思路类似，不同是程序不用依赖于crontab来唤醒，自己设置定时器搞定就行了。多进程/多线程/多协程 都能搞定多任务 - 黑夜路人

26. 我倒没考虑过并发，最近也在搞后台脚本，跑cron，每次取100或1000条，处理完，再按这个数量依次处理 - 酸酸哥

27. 先获取长度，然后按照长度切分 分别跑，抓出待处理的记录. 然后根据新的队列长度，重新切分 跑完按照一定数量级一次query再alert回去？遇到类似要修改纪录的场景，由于长度不算太长，都直接sql改了。。 - 萝莉控夫斯基

28. 切割+线程池 - 马犇

29. 数据从表里取出放队列里，由队列去控制并发 - 徐刚

30. //伪代码
$queryWhere = 'date > '.$startDate.' and date <= '.$endDate.'order by date desc';//通用限制条件
$countSql = 'select count(0) form tableName where '.$queryWhere;//获取总数sql
$perNum = 500;
$count = getCount($countSql);//获取总数
$processNum = ceil($count / $perNum);//计算开多少线程执行
for($i=0; $i < $processNum; $i++){
    //开线程执行下面代码
    {
        $startPos = $i * $perNum;
        $selectSql = 'select * from tableName '.$queryWhere. 'limit '.$startPos.','.$perNum;
        $data = getData($selectSql);
        doSomeThing()
    }
}
分段就可以避免并发  - 亢

31. 今天的话题以前有讨论过吧？我记得我有回复过，数据库的解决方案很成熟，最好的办法是按计划划分好数据段交给不同的线程/进程，不能划分且处理线程不太多时就用update改状态，类似乐观锁原理，我对付脑残的招行接口就是这么干的. 数据量超大就最好是处理完再入库，kafka真心不错 - 水浸街

32. 把未处理的数据有序话，每个进程处理固定的几个，进程共享处理的序号，感觉这样可以 - xx人