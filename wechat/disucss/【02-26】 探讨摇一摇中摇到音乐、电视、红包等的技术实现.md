> 转载自：<http://mp.weixin.qq.com/s?__biz=MzA3MDA2MjE2OQ==&mid=205090259&idx=1&sn=99b313bef4369d96f73095c1efa30598&scene=1#rd>

1. 最常用的一种方法就是对录音（wav波形声音）进行傅里叶变换，可以得出这段录音的频谱，也就是短时音调-时间图。不过由于录制录音的时候，环境不可能绝对安静，肯定会混有噪声，而且人声唱歌或多或少的会有走调，所以分析出来的这段音调不一定准确。可以通过判断短时能量及短时过零率去噪、频率-时间曲线平滑化去噪，以及基于统计的节拍修正、音调校准等方法进行修正。到了这时，仍然几乎不可能得到完全准确的音调序列。这时，便可以像字符串模糊匹配算法一样进行处理；也可以求带权值的编辑距离（也称为动态时间规整算法），距离越小越接近；或者直接从统计的角度，求方差；或者直接对比旋律升降趋势；都可以，上述方法对不同风格的歌曲检索的效果都不一样。当然，如果歌曲较多的话，还可以使用隐马尔科夫链对歌曲风格等特征进行分类，然后只在接近的类别里检索；以及并行检索等。此时的曲库里存的应该是每首歌的标准音调序列。
这个是我之前找的做法
这里就会有个问题，不知道大家发现没，一段音频如果要特征采集后存储，就会有不同的存储结果，采集的音频长度 - 学在囧途

2. 摇一摇只是触发，然后肯定要录音，传输，声音存储，然后于服务器存储数据精准匹配，返回结果。 核心应该就是声音存储 - 拉菲哥

3. 怎么识别出来我好奇这点
比如歌曲我唱的他怎么识别不出来
文字我觉得会有但感觉不是主要特征吧
主要还是声谱分析吧 - 淘小淘

4. 有一些走音严重的感觉要加个文字. 五音不全的 - 海浪@陈捷

5. 现在语音不都是概率方法吗 不是模式匹配了 - diwayou@高朋

6. 上次听过吴恩达讲机器学习的时候好像说过这个. 以前是靠海量的数据做支撑，现在是特征识别 - 二先生

7. 但是有个实时的问题. 电视是直播的.如果常规歌曲采用离线建库的方法没问题 - 黑夜路人

8. 按照时间分段存储吧. 去匹配的时候带上时间戳 - 李曉瑋

9. 看过wxg分享的资料，核心在音频指纹摘要，基于频带  峰值等多个因子特征。这个有很多公开文献提供算法模型。客户端已经做好摘要了，后台只需匹配。实时节目是实时采样入库的。貌似10s音频指纹才1k大小 - 楚吟风

10. 一个节目时间段还是漫长的了，所以这个实时其实相对的. 跟一个歌曲差不多吧 - 拉菲哥

11. 楼上已经有大神提过相关算法模型了。总之都是匹配特征了，肯定不会比较原始音频了. 延时在3到5s左右 - 楚吟风

12. 
采样定理在音乐上的应用 http://v.163.com/movie/2008/2/L/T/M7Q4BLENR_M7QDMM3LT.html - 学在囧途

13. http://djt.qq.com/video/1199  腾讯大讲堂有讲到一些，音乐识别和哼哈识别是不同的两种做法 - XiangZ

14. 声音采样值可以根据音准四舍五入
然后以特征值匹配
每个音有标准的频率
像钢琴都要调音 - 飛魚

15. 个人感觉摇一摇就跟游戏中的开宝箱一样，红包根据总金额随机 - 钱志强

16. 摇一摇，录一段音，传到云端跟电视时实片段的声音进行比对。基本可以判断是哪个台. 电视台本身就没多少个，比摇一摇搜歌简单的多。 - 如末

17. 感觉类似HMM在语音识别的应用，但是设计上应该有些不同，一般的语音识别语料库庞大，摇一摇需要匹配的语料库很小，但是并发很高，对这种CPU占用高的应用，如果我做的话，会把节目需要匹配的语音库预加载到微信（估计总大小不会上M吧，而且看电视的时候一般有wifi），然后用户摇的时候把运算结果回传给服务端 - chibs

18. 同意。这样一方面保证随机的平均，另一方面降低并发冲突 - Paris

【分享链接】

1. 红包统计学：为何有些人盆钵满盈，有些人入不敷出？ http://www.guokr.com/article/439983/ - Huangsir